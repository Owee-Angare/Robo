{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Robot Conversation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSaoWRL6c5qrPxx91m/OWb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Owee-Angare/Robo/blob/master/Robot_Conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsPzvLtzJtXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e76c80a4-84a8-49d8-f0c6-5930d3618686"
      },
      "source": [
        "import tensorflow as tf \n",
        "import tensorflow.keras as keras \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "df=pd.read_csv('RobotConversation.csv')  \n",
        "df "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num1</th>\n",
              "      <th>num2</th>\n",
              "      <th>num3</th>\n",
              "      <th>num4</th>\n",
              "      <th>num5</th>\n",
              "      <th>num6</th>\n",
              "      <th>num7</th>\n",
              "      <th>num8</th>\n",
              "      <th>num9</th>\n",
              "      <th>num10</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1747</td>\n",
              "      <td>1749</td>\n",
              "      <td>1751</td>\n",
              "      <td>1758</td>\n",
              "      <td>1765</td>\n",
              "      <td>1767</td>\n",
              "      <td>1772</td>\n",
              "      <td>1774</td>\n",
              "      <td>1.783000e+03</td>\n",
              "      <td>1.785000e+03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65056</td>\n",
              "      <td>195168</td>\n",
              "      <td>1561344</td>\n",
              "      <td>7806720</td>\n",
              "      <td>31226880</td>\n",
              "      <td>187361280</td>\n",
              "      <td>749445120</td>\n",
              "      <td>6745006080</td>\n",
              "      <td>6.745006e+09</td>\n",
              "      <td>6.745006e+09</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2855</td>\n",
              "      <td>2860</td>\n",
              "      <td>2865</td>\n",
              "      <td>2870</td>\n",
              "      <td>2875</td>\n",
              "      <td>2880</td>\n",
              "      <td>2885</td>\n",
              "      <td>2890</td>\n",
              "      <td>2.895000e+03</td>\n",
              "      <td>2.900000e+03</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11440</td>\n",
              "      <td>57200</td>\n",
              "      <td>286000</td>\n",
              "      <td>1430000</td>\n",
              "      <td>7150000</td>\n",
              "      <td>35750000</td>\n",
              "      <td>178750000</td>\n",
              "      <td>893750000</td>\n",
              "      <td>4.468750e+09</td>\n",
              "      <td>2.234375e+10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4444</th>\n",
              "      <td>33060</td>\n",
              "      <td>165300</td>\n",
              "      <td>826500</td>\n",
              "      <td>4132500</td>\n",
              "      <td>20662500</td>\n",
              "      <td>103312500</td>\n",
              "      <td>516562500</td>\n",
              "      <td>2582812500</td>\n",
              "      <td>1.291406e+10</td>\n",
              "      <td>6.457031e+10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4446</th>\n",
              "      <td>2071</td>\n",
              "      <td>2073</td>\n",
              "      <td>2081</td>\n",
              "      <td>2085</td>\n",
              "      <td>2094</td>\n",
              "      <td>2098</td>\n",
              "      <td>2101</td>\n",
              "      <td>2107</td>\n",
              "      <td>2.115000e+03</td>\n",
              "      <td>2.118000e+03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4447</th>\n",
              "      <td>35540</td>\n",
              "      <td>284320</td>\n",
              "      <td>568640</td>\n",
              "      <td>2843200</td>\n",
              "      <td>2843200</td>\n",
              "      <td>14216000</td>\n",
              "      <td>42648000</td>\n",
              "      <td>341184000</td>\n",
              "      <td>2.388288e+09</td>\n",
              "      <td>1.910630e+10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4448</th>\n",
              "      <td>1962</td>\n",
              "      <td>1967</td>\n",
              "      <td>1972</td>\n",
              "      <td>1977</td>\n",
              "      <td>1982</td>\n",
              "      <td>1987</td>\n",
              "      <td>1992</td>\n",
              "      <td>1997</td>\n",
              "      <td>2.002000e+03</td>\n",
              "      <td>2.007000e+03</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4449 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       num1    num2     num3  ...          num9         num10  source\n",
              "0         2       5        2  ...  1.000000e+00  3.000000e+00       0\n",
              "1      1747    1749     1751  ...  1.783000e+03  1.785000e+03       1\n",
              "2     65056  195168  1561344  ...  6.745006e+09  6.745006e+09       2\n",
              "3      2855    2860     2865  ...  2.895000e+03  2.900000e+03       3\n",
              "4     11440   57200   286000  ...  4.468750e+09  2.234375e+10       4\n",
              "...     ...     ...      ...  ...           ...           ...     ...\n",
              "4444  33060  165300   826500  ...  1.291406e+10  6.457031e+10       4\n",
              "4445      3       5        1  ...  2.000000e+00  4.000000e+00       0\n",
              "4446   2071    2073     2081  ...  2.115000e+03  2.118000e+03       1\n",
              "4447  35540  284320   568640  ...  2.388288e+09  1.910630e+10       2\n",
              "4448   1962    1967     1972  ...  2.002000e+03  2.007000e+03       3\n",
              "\n",
              "[4449 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_9_O2ViKqVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3917f710-5772-4739-8dc4-588b1d4823e4"
      },
      "source": [
        "#Input and Output \n",
        "x=df.iloc[:,0:10].values\n",
        "y=df.iloc[:,10].values \n",
        "y "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWxxWuM-KviV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining Keras model with 2 hidden layers and 1 outut layer\n",
        "model=tf.keras.Sequential()\n",
        "model.add(keras.layers.Dense(12,input_dim=10,activation='relu'))\n",
        "model.add(keras.layers.Dense(8,activation='relu'))\n",
        "model.add(keras.layers.Dense(5,activation='softmax')) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp1gN_SWK9Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy']) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsHaiMFeLIue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b3ae397-2a59-45b9-ac69-9e8bb526efba"
      },
      "source": [
        "model.fit(x,y,epochs=50) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 89953000.0000 - accuracy: 0.3940\n",
            "Epoch 2/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 39336744.0000 - accuracy: 0.3949\n",
            "Epoch 3/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 13697742.0000 - accuracy: 0.4608\n",
            "Epoch 4/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 39892648.0000 - accuracy: 0.4630\n",
            "Epoch 5/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 32968468.0000 - accuracy: 0.4799\n",
            "Epoch 6/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 7010180.0000 - accuracy: 0.5808\n",
            "Epoch 7/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4206258.5000 - accuracy: 0.6395\n",
            "Epoch 8/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1386428.3750 - accuracy: 0.6858\n",
            "Epoch 9/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 3591291.2500 - accuracy: 0.6945\n",
            "Epoch 10/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5573156.5000 - accuracy: 0.7238\n",
            "Epoch 11/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1228476.2500 - accuracy: 0.7633\n",
            "Epoch 12/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 30800822.0000 - accuracy: 0.7038\n",
            "Epoch 13/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 31977134.0000 - accuracy: 0.6372\n",
            "Epoch 14/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 6695218.5000 - accuracy: 0.6273\n",
            "Epoch 15/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1407587.5000 - accuracy: 0.7222\n",
            "Epoch 16/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1062661.5000 - accuracy: 0.7748\n",
            "Epoch 17/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 3525082.7500 - accuracy: 0.7485\n",
            "Epoch 18/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1946905.0000 - accuracy: 0.7777\n",
            "Epoch 19/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5114510.5000 - accuracy: 0.7719\n",
            "Epoch 20/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 2515741.0000 - accuracy: 0.7622\n",
            "Epoch 21/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4535063.0000 - accuracy: 0.7653\n",
            "Epoch 22/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 8827077.0000 - accuracy: 0.6635\n",
            "Epoch 23/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 6544291.0000 - accuracy: 0.6981\n",
            "Epoch 24/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4936256.5000 - accuracy: 0.7085\n",
            "Epoch 25/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1403498.3750 - accuracy: 0.7042\n",
            "Epoch 26/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5048903.5000 - accuracy: 0.7503\n",
            "Epoch 27/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 15086265.0000 - accuracy: 0.6790\n",
            "Epoch 28/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5096612.0000 - accuracy: 0.6808\n",
            "Epoch 29/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 9339564.0000 - accuracy: 0.6566\n",
            "Epoch 30/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5699522.0000 - accuracy: 0.6961\n",
            "Epoch 31/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 6911643.5000 - accuracy: 0.6615\n",
            "Epoch 32/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4876074.5000 - accuracy: 0.6437\n",
            "Epoch 33/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4935122.5000 - accuracy: 0.7145\n",
            "Epoch 34/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4332240.5000 - accuracy: 0.7181\n",
            "Epoch 35/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 3064274.0000 - accuracy: 0.6413\n",
            "Epoch 36/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4057765.2500 - accuracy: 0.7343\n",
            "Epoch 37/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 8072913.0000 - accuracy: 0.6824\n",
            "Epoch 38/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 3708789.2500 - accuracy: 0.6867\n",
            "Epoch 39/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 9473727.0000 - accuracy: 0.6912\n",
            "Epoch 40/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1927028.3750 - accuracy: 0.6869\n",
            "Epoch 41/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5478738.5000 - accuracy: 0.7206\n",
            "Epoch 42/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 8316803.5000 - accuracy: 0.6887\n",
            "Epoch 43/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 1101260.8750 - accuracy: 0.6628\n",
            "Epoch 44/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 2686386.5000 - accuracy: 0.7283\n",
            "Epoch 45/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 3689274.5000 - accuracy: 0.7278\n",
            "Epoch 46/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4535287.0000 - accuracy: 0.7193\n",
            "Epoch 47/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 8918057.0000 - accuracy: 0.7543\n",
            "Epoch 48/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 5273084.5000 - accuracy: 0.7638\n",
            "Epoch 49/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 4541793.5000 - accuracy: 0.7415\n",
            "Epoch 50/50\n",
            "140/140 [==============================] - 0s 1ms/step - loss: 2781194.7500 - accuracy: 0.7710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f768c0e7208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39YqP_Q2LLo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9192715a-7d7b-46a0-fc47-7a661a2a1461"
      },
      "source": [
        "predictions=model.predict_classes(x)\n",
        "predictions "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-d9b74ab33e9d>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 2, ..., 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIYbjQ99PQoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "995cc3b1-896c-4aae-e8de-c68849262fb4"
      },
      "source": [
        "y "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_kMJ5naPT4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f5a17db7-a1fe-45af-f8c4-7ca207de348e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix \n",
        "confusion_matrix (y,predictions) "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[890,   0,   0,   0,   0],\n",
              "       [  0, 696,  15, 179,   0],\n",
              "       [  0,   0, 880,   0,  10],\n",
              "       [  0, 711,   9, 170,   0],\n",
              "       [  0,   0, 889,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}